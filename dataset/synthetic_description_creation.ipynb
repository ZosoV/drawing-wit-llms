{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832e4d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/ankit/Desktop/Portfolio/kaggle/kaggle-experiments/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "data = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce5d727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"/mnt/c/Users/ankit/Desktop/Portfolio/kaggle/kaggle-experiments/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc8ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"**You are an advanced data generation assistant.**  \n",
    "Your goal is to generate high-quality synthetic data samples based on \n",
    "provided examples. Your output must be well-structured, \n",
    "logically sound, and formatted correctly. \n",
    "\n",
    "**Instructions:**\n",
    "1. **Follow the Structure**  \n",
    "   Each data sample must include:  \n",
    "   - **Description**: A clear, well-formed description of an SVG image.  \n",
    "   - **Rationale**: A step-by-step, reasoning process for generation of the Description.  \n",
    "\n",
    "2. **Output Format (Strict)**\n",
    "   - A list of json consisteing of five data samples\n",
    "```\n",
    "[{\"description\" : \"Generated description\"\n",
    "\"rationale\": \"reasoning why this description makes sense as a data sample\"},\n",
    "...\n",
    "]\n",
    "```\n",
    "\n",
    "**Now, generate 5 new data samples based on the given examples.**\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233b5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def process_response(content):\n",
    "    content = content.split(\"```json\")[1]\n",
    "    content = content.split(\"```\")[0]\n",
    "    return content.strip()\n",
    "\n",
    "\n",
    "def process_reresponse(content):\n",
    "    pattern = r\"```json(.*?)```\"\n",
    "    matches = re.findall(pattern, content)\n",
    "    if matches:\n",
    "        return matches[0].strip()\n",
    "    else:\n",
    "        return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6dcdd7",
   "metadata": {},
   "source": [
    "## 500 high quality samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44fdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from json import loads\n",
    "\n",
    "from llm import llm\n",
    "\n",
    "model = llm(model=\"gemini-2.5-flash-preview-04-17\", api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "model.messages.append({\"role\": \"system\", \"content\": SYSTEM_PROMPT})\n",
    "\n",
    "total_samples = 500\n",
    "num_samples_gen = 5\n",
    "sample_collection = []\n",
    "\n",
    "for i in range(int(total_samples / num_samples_gen)):\n",
    "    indices = [random.randrange(0, len(data)) for _ in range(num_samples_gen)]\n",
    "\n",
    "    USER_PROMPT = \"<examples>\" + \"\\n\".join(data[indices][\"description\"]) + \"</examples>\"\n",
    "\n",
    "    response = model(USER_PROMPT)\n",
    "\n",
    "    try:\n",
    "        samples = loads(process_response(response))\n",
    "    except Exception:\n",
    "        samples = [{\"description\": \"\"}] * num_samples_gen\n",
    "\n",
    "    for sample in samples:\n",
    "        sample_collection.append(sample[\"description\"])\n",
    "\n",
    "    model.messages.pop()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b91d79",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' type is unordered",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m dict_samples = {}\n\u001b[32m      3\u001b[39m dict_samples[\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m] = unique_sample_collection\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_save = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/ankit/Desktop/Portfolio/kaggle/kaggle-experiments/.venv/lib/python3.12/site-packages/pandas/core/frame.py:664\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    658\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    659\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    660\u001b[39m     )\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    663\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m664\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    666\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmrecords\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmrecords\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/ankit/Desktop/Portfolio/kaggle/kaggle-experiments/.venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:493\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    490\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    491\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/ankit/Desktop/Portfolio/kaggle/kaggle-experiments/.venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:123\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    120\u001b[39m         index = ensure_index(index)\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     arrays = \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[32m    125\u001b[39m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    129\u001b[39m \n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    131\u001b[39m     index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/ankit/Desktop/Portfolio/kaggle/kaggle-experiments/.venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:617\u001b[39m, in \u001b[36m_homogenize\u001b[39m\u001b[34m(data, index, dtype)\u001b[39m\n\u001b[32m    614\u001b[39m             val = \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[32m    615\u001b[39m         val = lib.fast_multiget(val, oindex._values, default=np.nan)\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m     val = \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_cast_failure\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     com.require_length_match(val, index)\n\u001b[32m    622\u001b[39m homogenized.append(val)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/ankit/Desktop/Portfolio/kaggle/kaggle-experiments/.venv/lib/python3.12/site-packages/pandas/core/construction.py:611\u001b[39m, in \u001b[36msanitize_array\u001b[39m\u001b[34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[39m\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    609\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mset\u001b[39m, \u001b[38;5;28mfrozenset\u001b[39m)):\n\u001b[32m    610\u001b[39m         \u001b[38;5;66;03m# Raise only for unordered sets, e.g., not for dict_keys\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m type is unordered\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    613\u001b[39m     \u001b[38;5;66;03m# materialize e.g. generators, convert e.g. tuples, abc.ValueView\u001b[39;00m\n\u001b[32m    614\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[33m\"\u001b[39m\u001b[33m__array__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    615\u001b[39m         \u001b[38;5;66;03m# e.g. dask array GH#38645\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'set' type is unordered"
     ]
    }
   ],
   "source": [
    "unique_sample_collection = set(sample_collection)\n",
    "dict_samples = {}\n",
    "dict_samples[\"description\"] = list(unique_sample_collection)\n",
    "\n",
    "df_save = pd.DataFrame(dict_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b223247",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_samples = {'description': list(dict_samples['description'])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f24c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_samples\n",
    "df_save = pd.DataFrame(dict_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d3ab5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save.to_csv(\"new_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a551f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
